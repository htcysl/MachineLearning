{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpwI7oMktDXTKo/drexLDW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/htcysl/MachineLearning/blob/main/TicTacToe_ReinforcementLearning_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Exmple of Reinforcement Learnig"
      ],
      "metadata": {
        "id": "gwRVMuaAM7gF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the necessary modeles :"
      ],
      "metadata": {
        "id": "jl1DKbCANL7z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26AAdvWwoQRV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining rows and columns\n",
        "BOARD_ROWS = 3\n",
        "BOARD_COLS = 3"
      ],
      "metadata": {
        "id": "UcX49Wdqoce1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a function for the different states that we can take\n",
        "class State:\n",
        "  def __init__(self,p1,p2):\n",
        "    self.board = np.zeros((BOARD_ROWS,BOARD_COLS))\n",
        "    self.p1 = p1\n",
        "    self.p2 = p2\n",
        "    self.isEnd = False\n",
        "    self.boardHash = None\n",
        "    # init p1 players first\n",
        "    self.playerSymbol = 1\n",
        "\n",
        "  #  The actions taken on the board will have to be stored as a hash function\n",
        "  def getHash(self) :\n",
        "    # Storing action\n",
        "    self.boardHash = str(self.board.reshape(BOARD_COLS*BOARD_ROWS))\n",
        "    return self.boardHash\n",
        "\n",
        "  # Define a function to find the winner of the game :\n",
        "  def winner(self) :\n",
        "    # row\n",
        "    for i in range(BOARD_ROWS):\n",
        "      if sum(self.board[i,:]) == 3 :\n",
        "        self.isEnd = True\n",
        "        return 1\n",
        "      if sum(self.board[i,:]) == -3 :\n",
        "        self.iEnd = True\n",
        "        return -1\n",
        "\n",
        "    # col\n",
        "    for i in range(BOARD_COLS):\n",
        "      if sum(self.board[:,i]) == 3 :\n",
        "        self.isEnd = True\n",
        "        return 1\n",
        "      if sum(self.board[:,i]) == -3 :\n",
        "        self.isEnd = True\n",
        "        return 1\n",
        "      if sum(self.board[:,i]) == -3 :\n",
        "        self.isEnd = True\n",
        "        return -1\n",
        "\n",
        "    # diagonal\n",
        "    diag_sum1 = sum([self.board[i,i] for i in range(BOARD_COLS)] )\n",
        "    diag_sum2 = sum([self.board[i,BOARD_COLS-i-1] for i in range(BOARD_COLS)])\n",
        "    diag_sum = max(diag_sum1,diag_sum2)\n",
        "    if diag_sum == 3 :\n",
        "      self.isEnd = True\n",
        "      return 1\n",
        "    if diag_sum == -3 :\n",
        "      self.isEnd = True\n",
        "      return -1\n",
        "\n",
        "    # The game also ended with in a tie / No available positions\n",
        "    if len(self.availablePositions()) == 0 :\n",
        "      self.isEnd = True\n",
        "      return 0\n",
        "\n",
        "    # not end\n",
        "    self.isEnd = False\n",
        "    return  None\n",
        "\n",
        "  # Define a function to keep track of the available positions on the board\n",
        "  def availablePositions(self) :\n",
        "    positions = []\n",
        "    for i in range(BOARD_ROWS) :\n",
        "      for j in range(BOARD_COLS) :\n",
        "        if self.board[i,j] == 0 :\n",
        "          positions.append((i,j)) # need to be tuple\n",
        "    return positions\n",
        "\n",
        "  # Define a function to update the state\n",
        "  def updateState(self,position):\n",
        "    self.board[position] = self.playerSymbol\n",
        "    # switch to another player\n",
        "    self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
        "\n",
        "  # Define a reward function and only when gane ends\n",
        "  def giveReward(self) :\n",
        "    result = self.winner()\n",
        "    # backpropagate reward\n",
        "    if result == 1 :\n",
        "      self.p1.feedReward(1)\n",
        "      self.p2.feedReward(0)\n",
        "    elif result == -1 :\n",
        "      self.p1.feedReward(0)\n",
        "      self.p2.feedReward(1)\n",
        "    else :\n",
        "      self.p1.feedReward(0.1)\n",
        "      self.p2.feedReward(0.5)\n",
        "\n",
        "  # After the game is over, we need to reset the borad\n",
        "  def reset(self):\n",
        "    self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "    self.boardHash = None\n",
        "    self.isEnd = False\n",
        "    self.playerSymbol = 1\n",
        "\n",
        "  # Define the main play function between two opponents we will use this to train the model:\n",
        "  def play(self, rounds=100) :\n",
        "    for i in range(rounds) :\n",
        "      print(\"Rounds {}\".format(i))\n",
        "      while not self.isEnd :\n",
        "        # Player 1\n",
        "        positions = self.availablePositions()\n",
        "        p1_action = self.p1.chooseAction(positions, self.board,self.playerSymbol)\n",
        "        # take action and update board state\n",
        "        self.updateState(p1_action)\n",
        "        board_hash = self.getHash()\n",
        "        self.p1.addState(board_hash)\n",
        "        # check board status if it is end\n",
        "\n",
        "        win = self.winner()\n",
        "        if win is not None :\n",
        "          # self.showBoard()\n",
        "          # ended with p1 either win or draw\n",
        "          self.giveReward()\n",
        "          self.p1.reset()\n",
        "          self.p2.reset()\n",
        "          self.reset()\n",
        "          break\n",
        "        else :\n",
        "          # player 2\n",
        "          positions = self.availablePositions()\n",
        "          p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
        "          self.updateState(p2_action)\n",
        "          board_hash = self.getHash()\n",
        "          self.p2.addState(board_hash)\n",
        "\n",
        "          win = self.winner()\n",
        "          if win is not None:\n",
        "            # self.showBoard()\n",
        "            # ended with p2 either win or draw\n",
        "            self.giveReward()\n",
        "            self.p1.reset()\n",
        "            self.p2.reset()\n",
        "            self.reset()\n",
        "            break\n",
        "  # Define a function to pay the actual game :\n",
        "  def play2(self) :\n",
        "    while not self.isEnd:\n",
        "        # Player 1\n",
        "        positions = self.availablePositions()\n",
        "        p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
        "        # take action and update board state\n",
        "        self.updateState(p1_action)\n",
        "        self.showBoard()\n",
        "        # check board status if it is end\n",
        "        win = self.winner()\n",
        "        if win is not None :\n",
        "          if win == 1 :\n",
        "            print(self.p1.name,\"wins!\")\n",
        "          else :\n",
        "            print(\"tie!\")\n",
        "          self.reset()\n",
        "          break\n",
        "        else :\n",
        "          # Player 2\n",
        "          positions = self.availablePositions()\n",
        "          p2_action = self.p2.chooseAction(positions)\n",
        "\n",
        "          self.updateState(p2_action)\n",
        "          self.showBoard()\n",
        "          win = self.winner()\n",
        "          if win is not None:\n",
        "            if win == -1 :\n",
        "              print(self.p2.name, \"wins!\")\n",
        "            else :\n",
        "              print(\"tie!\")\n",
        "            self.reset()\n",
        "            break\n",
        "\n",
        "  # Show the board on the terminal\n",
        "  def showBoard(self) :\n",
        "    # p1: x p2 : o\n",
        "    for i in range(0, BOARD_ROWS) :\n",
        "      print(\"----------------\")\n",
        "      token = \"\"\n",
        "      out = '| '\n",
        "      for j in range(0,BOARD_COLS) :\n",
        "        if self.board[i,j] == 1:\n",
        "          token = 'x'\n",
        "        if self.board[i,j] == -1 :\n",
        "          token = 'o'\n",
        "        if self.board[i,j] == 0 :\n",
        "          token = ' '\n",
        "        out += token + ' |'\n",
        "      print(out)\n",
        "    print(\"----------------\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dbi_fafoOCLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Define a player class to instantiate players and define the policy. The will be used to train the model\n",
        "class Player :\n",
        "   def __init__(self, name, exp_rate=0.3 ):\n",
        "     self.name = name\n",
        "     self.states = []  # record all positions taken\n",
        "     self.lr = 0.2\n",
        "     self.exp_rate = exp_rate\n",
        "     self.decay_gamma = 0.9\n",
        "     self.states_value = {}  # state -> value\n",
        "\n",
        "   def getHash(self, board) :\n",
        "    boardHash = str(board.reshape(BOARD_COLS*BOARD_ROWS))\n",
        "    return boardHash\n",
        "\n",
        "   # chosing action for the player and defining state:\n",
        "   def chooseAction(self, positions, current_board, symbol) :\n",
        "    if np.random.uniform(0,1): # self.exp_rate:\n",
        "       # take random action\n",
        "       idx = np.random.choice(len(positions))\n",
        "       action = positions[idx]\n",
        "    else :\n",
        "      value_max = -999\n",
        "      for p in positions :\n",
        "        next_board = current_board.copy()\n",
        "        next_board[p] = symbol\n",
        "        next_boardHash = self.getHash(next_board)\n",
        "        value = 0 if self.states_value.get(next_board)  is None else self.states_value.get(next_boardHash)\n",
        "        # print(\"value\",value)\n",
        "        if value >= value_max :\n",
        "          value_max = value\n",
        "          action = p\n",
        "    #print(\"{} takes action {}\".format(self.name,action))\n",
        "    return action\n",
        "\n",
        "  # append a hash state\n",
        "   def addState(self, state) :\n",
        "     self.states.append(state)\n",
        "\n",
        "   # Define the reward function and save the policy\n",
        "   def feedReward(self, reward) :\n",
        "     for st in reversed(self.states) :\n",
        "       if self.states_value.get(st) is None :\n",
        "         self.states_value[st] = 0\n",
        "       self.states_value[st] += self.lr*(self.decay_gamma*reward - self.states_value[st])\n",
        "       reward = self.states_value[st]\n",
        "\n",
        "\n",
        "   def reset(self) :\n",
        "     self.status = []\n",
        "\n",
        "   def savePolicy(self) :\n",
        "     fw = open(\"policy_\"+str(self.name), \"wb\")\n",
        "     pickle.dump(self.states_value,fw)\n",
        "     fw.close()\n",
        "\n",
        "   def loadPolicy(self, file) :\n",
        "     fr = open(file,'rb')\n",
        "     self.states_value = pickle.load(fr)\n",
        "     fr.close()"
      ],
      "metadata": {
        "id": "4Mu4hcT2Xhnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vAC7AJcHqmhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a class that will be called when the player has to take an action\n",
        "class HumanPlayer :\n",
        "  def __init__(self,name) :\n",
        "    self.name = name\n",
        "\n",
        "  def chooseAction(self, positions) :\n",
        "    while True :\n",
        "       row = int(input(\"Input your action row:\"))\n",
        "       col = int(input(\"Input your action col:\"))\n",
        "       action = (row,col)\n",
        "       if action in positions :\n",
        "        return action\n",
        "\n",
        "  def addState(self, state) :\n",
        "    pass\n",
        "  def feedReward(self, reward) :\n",
        "    pass\n",
        "  def reset(self) :\n",
        "    pass"
      ],
      "metadata": {
        "id": "sXfeRW4Ds5PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = Player(\"p1\")\n",
        "p2 = Player(\"p2\")\n",
        "\n",
        "st = State(p1,p2)\n",
        "print(\"training .... \")\n",
        "st.play(50000)"
      ],
      "metadata": {
        "id": "B9L5ELsXtu9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1.savePolicy()\n",
        "p2.savePolicy()"
      ],
      "metadata": {
        "id": "wsWAB2SYIkMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1.loadPolicy(\"policy_p1\")"
      ],
      "metadata": {
        "id": "9Y_iFIcBItBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = Player(\"computer\",exp_rate=0)\n",
        "p1.loadPolicy(\"policy_p1\")\n",
        "\n",
        "p2 = HumanPlayer(\"human\")\n",
        "\n",
        "st = State(p1,p2)\n",
        "st.play2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2UN-_PcIywm",
        "outputId": "bca3aa3d-e78d-410e-b347-f53bc5feccb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------\n",
            "|   |  |  |\n",
            "----------------\n",
            "|   |  |  |\n",
            "----------------\n",
            "|   |  |x |\n",
            "----------------\n",
            "Input your action row:1\n",
            "Input your action col:1\n",
            "----------------\n",
            "|   |  |  |\n",
            "----------------\n",
            "|   |o |  |\n",
            "----------------\n",
            "|   |  |x |\n",
            "----------------\n",
            "----------------\n",
            "|   |  |x |\n",
            "----------------\n",
            "|   |o |  |\n",
            "----------------\n",
            "|   |  |x |\n",
            "----------------\n",
            "Input your action row:2\n",
            "Input your action col:1\n",
            "----------------\n",
            "|   |  |x |\n",
            "----------------\n",
            "|   |o |  |\n",
            "----------------\n",
            "|   |o |x |\n",
            "----------------\n",
            "----------------\n",
            "|   |  |x |\n",
            "----------------\n",
            "|   |o |  |\n",
            "----------------\n",
            "| x |o |x |\n",
            "----------------\n",
            "Input your action row:0\n",
            "Input your action col:0\n",
            "----------------\n",
            "| o |  |x |\n",
            "----------------\n",
            "|   |o |  |\n",
            "----------------\n",
            "| x |o |x |\n",
            "----------------\n",
            "----------------\n",
            "| o |x |x |\n",
            "----------------\n",
            "|   |o |  |\n",
            "----------------\n",
            "| x |o |x |\n",
            "----------------\n",
            "Input your action row:1\n",
            "Input your action col:0\n",
            "----------------\n",
            "| o |x |x |\n",
            "----------------\n",
            "| o |o |  |\n",
            "----------------\n",
            "| x |o |x |\n",
            "----------------\n",
            "----------------\n",
            "| o |x |x |\n",
            "----------------\n",
            "| o |o |x |\n",
            "----------------\n",
            "| x |o |x |\n",
            "----------------\n",
            "computer wins!\n"
          ]
        }
      ]
    }
  ]
}